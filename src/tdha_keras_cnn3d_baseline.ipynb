{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "wx-SND-5CNR1"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from utils.load_bold_data import load_multisite_data\n",
        "import numpy as np, torch\n",
        "from torch.utils.data import Dataset\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_rois = 18\n",
        "n_splits = 5\n",
        "n_repeats = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QPijd9hlHxIS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, GlobalAveragePooling3D, Conv2D, Input, GlobalAveragePooling2D, MaxPooling2D, Flatten, Dense, InputLayer, Dropout, TimeDistributed, LSTM\n",
        "\n",
        "\n",
        "timesteps = 172    # número de imágenes en la secuencia\n",
        "height = 18\n",
        "width = 18\n",
        "channels = 1\n",
        "\n",
        "def create_model():\n",
        "  inputs = Input(shape=(timesteps, height, width, channels))\n",
        "\n",
        "  x = Conv3D(32, (3,3,3), activation='relu')(inputs)\n",
        "  x = MaxPooling3D((1,2,2))(x)\n",
        "\n",
        "  x = Conv3D(64, (3,3,3), activation='relu')(x)\n",
        "  x = GlobalAveragePooling3D()(x)\n",
        "\n",
        "  x = Dense(96, activation='relu')(x)\n",
        "\n",
        "  outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs, outputs)\n",
        "   \n",
        "  model.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy', 'precision', 'recall'])\n",
        "  # Resumen del modelo\n",
        "  return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0CJzBjBFwuH",
        "outputId": "00cc8b0d-d24c-4a82-9b4a-694d814af97b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(177, 172, 18, 18)\n"
          ]
        }
      ],
      "source": [
        "X = joblib.load(f\"../data/fcm-fisher/X_172_{n_rois}.joblib\")\n",
        "y = joblib.load(f\"../data/fcm-fisher/y_172_{n_rois}.joblib\")\n",
        "\n",
        "# Display the shape of the concatenated array\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HwugROxRrx4",
        "outputId": "261c89c2-ab48-4079-b9d1-57459469db42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1/5\n",
            "Epoch 11: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Validation Accuracy: 0.5000\n",
            "Validation Precision: 0.0000\n",
            "Validation Recall: 0.0000\n",
            "Fold 2/5\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Validation Accuracy: 0.5000\n",
            "Validation Precision: 0.0000\n",
            "Validation Recall: 0.0000\n",
            "Fold 3/5\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Validation Accuracy: 0.5143\n",
            "Validation Precision: 0.5143\n",
            "Validation Recall: 1.0000\n",
            "Fold 4/5\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Validation Accuracy: 0.5143\n",
            "Validation Precision: 0.5143\n",
            "Validation Recall: 1.0000\n",
            "Fold 5/5\n",
            "Epoch 10: early stopping\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Validation Accuracy: 0.5143\n",
            "Validation Precision: 0.5143\n",
            "Validation Recall: 1.0000\n",
            "\n",
            "Average Cross-Validation Scores:\n",
            "Accuracy: 0.5086 +- 0.0070\n",
            "Precision: 0.3086 +- 0.2519\n",
            "Recall: 0.6000 +- 0.4899\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "\n",
        "\n",
        "skf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats)\n",
        "# Initialize lists to store results\n",
        "accuracy_scores = []\n",
        "precision_scores = []\n",
        "recall_scores = []\n",
        "\n",
        "# Define Early Stopping callback\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    min_delta=1e-4,\n",
        "    mode='max',\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "# Perform cross-validation\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(X, y)):\n",
        "    print(f\"Fold {fold+1}/{n_splits*n_repeats}\")\n",
        "\n",
        "    # Split data into training and validation sets for the current fold\n",
        "    X_train, X_val = X[train_index], X[val_index]\n",
        "    y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "    # Create a new model for each fold to ensure independent training\n",
        "    model = create_model()\n",
        "\n",
        "    # Define a ModelCheckpoint callback to save the best model weights\n",
        "    checkpoint_filepath = f'tmp_keras_checkpoint/best_model_fold_{fold+1}.keras'\n",
        "    model_checkpoint_callback = ModelCheckpoint(\n",
        "        filepath=checkpoint_filepath,\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Train the model with the callbacks\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        epochs=100, # Increased epochs to allow Early Stopping to trigger\n",
        "        batch_size=32,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[model_checkpoint_callback, early_stopping_callback],\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    # Load the best model weights before evaluating\n",
        "    best_model = create_model() # Create a new model instance with the same architecture\n",
        "    best_model.load_weights(checkpoint_filepath)\n",
        "    loss, accuracy, precision, recall = best_model.evaluate(X_val, y_val, verbose=0)\n",
        "    if logging:\n",
        "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Validation Precision: {precision:.4f}\")\n",
        "        print(f\"Validation Recall: {recall:.4f}\")\n",
        "    # Store the scores\n",
        "    accuracy_scores.append(accuracy)\n",
        "    precision_scores.append(precision)\n",
        "    recall_scores.append(recall)\n",
        "\n",
        "# Print average scores across all folds\n",
        "print(\"\\nAverage Cross-Validation Scores:\")\n",
        "print(f\"Accuracy: {np.mean(accuracy_scores):.4f} +- {np.std(accuracy_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precision_scores):.4f} +- {np.std(precision_scores):.4f}\")\n",
        "print(f\"Recall: {np.mean(recall_scores):.4f} +- {np.std(recall_scores):.4f}\")\n",
        "df_results = pd.DataFrame(\n",
        "    {\"accuracy\": accuracy_scores,\n",
        "    \"precision\": precision_scores,\n",
        "    \"recall\": recall_scores}\n",
        ")\n",
        "df_results.to_csv(f\"tmp_results/results_{n_rois}_rois.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqwGhfEAHt13"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEO3CXJoAAm0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
